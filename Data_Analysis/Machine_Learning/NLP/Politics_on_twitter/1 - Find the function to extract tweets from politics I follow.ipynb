{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388aeddf",
   "metadata": {},
   "source": [
    "# Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64fc90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import unidecode\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437b7c1",
   "metadata": {},
   "source": [
    "# Import keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d46f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_data import keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1d9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api_key = keys.twitter_api_key()\n",
    "twitter_api_secret_key = keys.twitter_api_key_secret()\n",
    "twitter_bearer_token = keys.twitter_bearer_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bdc037",
   "metadata": {},
   "source": [
    "# Connect my developer project to my twitter profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5f751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authorize?oauth_token=R0Fn5QAAAAABUe3MAAABfNZXDSw\n"
     ]
    }
   ],
   "source": [
    "callback_uri = \"oob\" # url\n",
    "auth = tweepy.OAuthHandler(twitter_api_key, twitter_api_secret_key, callback_uri)\n",
    "redirect_url = auth.get_authorization_url()\n",
    "print(redirect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73561702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1928120398.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_31346/1928120398.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    m=\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "m="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214091d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# webbrowser.open(redirect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9a2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pin_value = '8886695'\n",
    "auth.get_access_token(user_pin_value)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(auth.access_token, auth.access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bd3a4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ceb0ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Generate IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574838ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# url = \"https://api.twitter.com/1.1/friends/ids.json?screen_name=alecoursonnois\"\n",
    "# response = requests.get(url, headers={'Authorization': f'Bearer {twitter_bearer_token}'})\n",
    "# ids = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70d703",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7d9aa",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ids_list = ids[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31fa6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# len(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0c307",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2961a07",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Generate tweets from IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20745ed1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ids_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3492765",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# counter = 1\n",
    "# for id in ids_list:\n",
    "#     url = f\"https://api.twitter.com/2/tweets/{id}?expansions=author_id,attachments.poll_ids\"\n",
    "#     response = requests.get(url, headers={'Authorization': 'Bearer {twitter_bearer_token}'})\n",
    "#     last_tweet_per_id = response.json()\n",
    "#     print(f\"{counter} : {id} : {last_tweet_per_id}\")\n",
    "#     print(\"---------------------------\")\n",
    "#     counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170be0d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# url = \"https://api.twitter.com/2/tweets/1446733333170380811\"\n",
    "# response = requests.get(url, headers={'Authorization': 'Bearer {twitter_bearer_token}'})\n",
    "# extracted_tweet = response.json()\n",
    "# extracted_tweet[\"data\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966539c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# extracted_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0652d8",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Build the main function to extract tweets from a timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611b857",
   "metadata": {
    "hidden": true
   },
   "source": [
    "url tuto : https://www.youtube.com/watch?v=dvAurfBB6Jk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef7811",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# api_attributes = dir(api)\n",
    "# api_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31db4163",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# my_timeline = api.home_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fec775",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Extract status from my_timeline\n",
    "\n",
    "# for status in my_timeline:\n",
    "#     print(status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf52ee8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## First step from the video\n",
    "\n",
    "# columns = set()\n",
    "# allowed_types = [str, int]\n",
    "# tweets_data = []\n",
    "\n",
    "# for status in my_timeline:\n",
    "# #     print(vars(status))\n",
    "# #     print('-----------------------------')\n",
    "# #     print(status.user.screen_name)\n",
    "#     status_dict = dict(vars(status))\n",
    "#     keys = vars(status).keys()\n",
    "#     single_tweet_data = {\"user\":status.user.screen_name, \"author\": status.author.screen_name}\n",
    "#     for k in keys:\n",
    "# #         print(k)\n",
    "#         v_type = type(status_dict[k])\n",
    "#         if v_type in allowed_types:\n",
    "#             single_tweet_data[k] = status_dict[k]\n",
    "#             columns.add(k)\n",
    "#     tweets_data.append(single_tweet_data)\n",
    "    \n",
    "# headers_cols = list(columns)\n",
    "# headers_cols.append(\"user\")\n",
    "# headers_cols.append(\"author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ff003",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Generate a df from the code above\n",
    "# df = pd.DataFrame(tweets_data, columns = headers_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc69d75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980410e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030be00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Write a first function to automatically extract tweets from my timeline\n",
    "\n",
    "# def extract_timeline_as_df(user_name):\n",
    "#     columns = set()\n",
    "#     allowed_types = [str, int]\n",
    "#     tweets_data = []\n",
    "#     if user_name == \"alecoursonnois\":\n",
    "#         timeline_list = api.home_timeline()\n",
    "#     else:\n",
    "#         timeline_list = api.get_user(screen_name=user_name).timeline()\n",
    "    \n",
    "#     for status in timeline_list:\n",
    "#         status_dict = dict(vars(status))\n",
    "#         keys = vars(status).keys()\n",
    "#         single_tweet_data = {\"user\":status.user.screen_name, \"author\": status.author.screen_name}\n",
    "#         for k in keys:\n",
    "#             v_type = type(status_dict[k])\n",
    "#             if v_type in allowed_types:\n",
    "#                 single_tweet_data[k] = status_dict[k]\n",
    "#                 columns.add(k)\n",
    "#         tweets_data.append(single_tweet_data)\n",
    "\n",
    "#     headers_cols = list(columns)\n",
    "#     headers_cols.append(\"user\")\n",
    "#     headers_cols.append(\"author\")\n",
    "    \n",
    "#     df = pd.DataFrame(tweets_data, columns = headers_cols)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b61b4d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Apply the function to extract tweets from a timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ca841",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### My timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bad8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df2 = extract_timeline_as_df(user_name=\"alecoursonnois\")\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed987d81",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Another user's timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4031e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df3 = extract_timeline_as_df(user_name=\"MLP_officiel\")\n",
    "# df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b6f92",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df4 = extract_timeline_as_df(user_name=\"Anne_Hidalgo\")\n",
    "# print(df4.shape)\n",
    "# df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24afd5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get tweets with ids using tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc9fec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# status_obj = api.get_status(\"1446730042839650311\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c20c2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# status_obj.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7a0fa",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get id with user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabe2e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# user = api.get_user(screen_name=\"Anne_Hidalgo\")\n",
    "# user_timeline = user.timeline()\n",
    "# user_id = user_timeline[0].id\n",
    "# user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d368c46",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Number of friends by user's screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07742c9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# me = api.get_user(screen_name=\"alecoursonnois\")\n",
    "# me.friends_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a2d7f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get the screen_name of politics that I follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d8740",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# my_friends = me.friends(count=100)\n",
    "# personal_friends = [\"Baly_5\", \"LucieCMP\", \"JeannonoSmith\", \"Seezzy_\"]\n",
    "# politics_screen_name = []\n",
    "\n",
    "# for friend in my_friends:\n",
    "#     friend_name = friend.screen_name\n",
    "#     if friend_name in personal_friends:\n",
    "#         pass\n",
    "#     else:\n",
    "#         politics_screen_name.append(friend_name)\n",
    "\n",
    "# print(f\"I follow {len(politics_screen_name)} politics\")\n",
    "# politics_screen_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd893808",
   "metadata": {},
   "source": [
    "# Load new content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f5fb7",
   "metadata": {},
   "source": [
    "## Function to extract the tweets of politicals that I follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e2edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets_from_politics(number_of_tweet_per_politic):\n",
    "    \"\"\"This function return a DataFrame of the last tweets of politics that I follow on Twitter\"\"\"\n",
    "    \n",
    "    # Start by working on my own account\n",
    "    me = api.get_user(screen_name=\"alecoursonnois\")\n",
    "    # Generate a list of my all of my friends (considering that I have under 200 friends on twitter)\n",
    "    my_friends = me.friends(count=200)\n",
    "    \n",
    "    # Retrieve my personal friends which I don't want to analyze their tweets\n",
    "    not_politics = [\"alecoursonnois\", \"Baly_5\", \"LucieCMP\", \"JeannonoSmith\", \"Seezzy_\"]\n",
    "    \n",
    "    # Create a set to stock the DataFrame columns names\n",
    "    columns = set()\n",
    "    # Create a list to restrict the extractions to string and int datas only\n",
    "    allowed_types = [str, int]\n",
    "    # Create a list to save each tweet and its datas\n",
    "    tweets_data = []\n",
    "    # Create to save politics screen_names\n",
    "    politics_screen_name = []\n",
    "    \n",
    "    # Iterate on my_friends\n",
    "    for friend in my_friends:\n",
    "        friend_name = friend.screen_name\n",
    "        \n",
    "        # Don't act if this friend is out of the project\n",
    "        if friend_name in not_politics:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            # Generate politics timeline list of the last tweets (the number must be indicated as a function's argument)\n",
    "            timeline_list = api.get_user(screen_name=friend_name).timeline(count=number_of_tweet_per_politic)\n",
    "            \n",
    "            # Iterate on each tweet\n",
    "            for status in timeline_list:\n",
    "                # Generate a dictionary of status attributes\n",
    "                status_dict = dict(vars(status))\n",
    "                \n",
    "                # From this dictionary, get the keys and stock it in a variable\n",
    "                keys = vars(status).keys()\n",
    "                \n",
    "                # Create a dictionary stocking each status of the politic we are working on\n",
    "                # Integrate the status user_screen_name and its author_screen_name\n",
    "                # This dictionary will be added to the \"tweets_data\" list and finaly convert into a DataFrame\n",
    "                single_tweet_data = {\"user\":status.user.screen_name, \"author\": status.author.screen_name}\n",
    "               \n",
    "                # Iterate on each status key (future column name)\n",
    "                for k in keys:\n",
    "                    # Check its type\n",
    "                    v_type = type(status_dict[k])\n",
    "                    \n",
    "                    # If its in the allowed_types list there we go\n",
    "                    if v_type in allowed_types:\n",
    "                        # Add the status data to its right key into the dictionary of each status\n",
    "                        single_tweet_data[k] = status_dict[k]\n",
    "                        # Add the key as a column name in the set\n",
    "                        columns.add(k)\n",
    "                \n",
    "                # Append the full single_tweet_data dictionary with the right key to the tweets_data list\n",
    "                tweets_data.append(single_tweet_data)\n",
    "\n",
    "    # Give a name to the columns respecting the order\n",
    "    headers_cols = list(columns)\n",
    "    # Add user and author column names\n",
    "    headers_cols.append(\"user\")\n",
    "    headers_cols.append(\"author\")\n",
    "\n",
    "    # Convert the tweets_data list into a DataFrame\n",
    "    df = pd.DataFrame(tweets_data)\n",
    "    \n",
    "    # Only keep columns that provides information\n",
    "#     columns_to_keep = ['user', 'author', 'id', 'text', 'source', 'source_url']\n",
    "#     df = df[columns_to_keep]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e489b9b",
   "metadata": {},
   "source": [
    "## Apply the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e2dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_tweets_df = extract_tweets_from_politics(number_of_tweet_per_politic=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87421c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>source_url</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1454743807824650240</td>\n",
       "      <td>1454743807824650240</td>\n",
       "      <td>À quoi sert la COP26 ? https://t.co/mcdo7zEuAG...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1452597557557821440</td>\n",
       "      <td>1452597557557821440</td>\n",
       "      <td>Engagez-vous pour un réel renouvellement de no...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1452290369727647757</td>\n",
       "      <td>1452290369727647757</td>\n",
       "      <td>Ou comment l'homme le plus détesté de France p...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1449692171012030466</td>\n",
       "      <td>1449692171012030466</td>\n",
       "      <td>Nouvelle vidéo sur les raisons de l'abstention...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1448651097082531855</td>\n",
       "      <td>1448651097082531855</td>\n",
       "      <td>@Cau_Marie_ Pouvez-vous m'envoyer un message o...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fr</td>\n",
       "      <td>1.265168e+18</td>\n",
       "      <td>1265168297236062208</td>\n",
       "      <td>Cau_Marie_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user         author                   id               id_str  \\\n",
       "0  MartinRocca12  MartinRocca12  1454743807824650240  1454743807824650240   \n",
       "1  MartinRocca12  MartinRocca12  1452597557557821440  1452597557557821440   \n",
       "2  MartinRocca12  MartinRocca12  1452290369727647757  1452290369727647757   \n",
       "3  MartinRocca12  MartinRocca12  1449692171012030466  1449692171012030466   \n",
       "4  MartinRocca12  MartinRocca12  1448651097082531855  1448651097082531855   \n",
       "\n",
       "                                                text           source  \\\n",
       "0  À quoi sert la COP26 ? https://t.co/mcdo7zEuAG...  Twitter Web App   \n",
       "1  Engagez-vous pour un réel renouvellement de no...  Twitter Web App   \n",
       "2  Ou comment l'homme le plus détesté de France p...  Twitter Web App   \n",
       "3  Nouvelle vidéo sur les raisons de l'abstention...  Twitter Web App   \n",
       "4  @Cau_Marie_ Pouvez-vous m'envoyer un message o...  Twitter Web App   \n",
       "\n",
       "                   source_url  retweet_count  favorite_count lang  \\\n",
       "0  https://mobile.twitter.com              0               1   fr   \n",
       "1  https://mobile.twitter.com              3               3   fr   \n",
       "2  https://mobile.twitter.com              0               1   fr   \n",
       "3  https://mobile.twitter.com              1               0   fr   \n",
       "4  https://mobile.twitter.com              0               0   fr   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_user_id_str in_reply_to_screen_name  \\\n",
       "0                  NaN                     NaN                     NaN   \n",
       "1                  NaN                     NaN                     NaN   \n",
       "2                  NaN                     NaN                     NaN   \n",
       "3                  NaN                     NaN                     NaN   \n",
       "4         1.265168e+18     1265168297236062208              Cau_Marie_   \n",
       "\n",
       "   quoted_status_id quoted_status_id_str  in_reply_to_status_id  \\\n",
       "0               NaN                  NaN                    NaN   \n",
       "1               NaN                  NaN                    NaN   \n",
       "2               NaN                  NaN                    NaN   \n",
       "3               NaN                  NaN                    NaN   \n",
       "4               NaN                  NaN                    NaN   \n",
       "\n",
       "  in_reply_to_status_id_str  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "070cdfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ad9f2d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# last_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b38f8",
   "metadata": {},
   "source": [
    "## Add features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba88834",
   "metadata": {},
   "source": [
    "- Parti politique \n",
    "- Tendance politique\n",
    "- Date d'extraction (pour intégrer cette information il faudrait créer une copie de l'archive sans cette colonne pour pouvoir retirer les doublons, puis, merger le df sans doublon au sauvegardé pour avoir la date d'extraction)\n",
    "- Score par lexique (plus tard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63738867",
   "metadata": {},
   "source": [
    "### Generate new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f81b28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(global_df[\"user\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a9e7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = [{\"user\":'EPhilippe_LH', \"political_party\":\"horizons\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'ZemmourEric', \"political_party\":\"zemmour\", \"political_trend\":\"extrem_right\"},\n",
    "                 {\"user\":'EmmanuelMacron', \"political_party\":\"LREM\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'Waechter2022', \"political_party\":\"mouvement_ecologiste_independant\", \"political_trend\":\"ecology\"},\n",
    "                 {\"user\":'Fabien_Roussel', \"political_party\":\"PCF\", \"political_trend\":\"extrem_left\"},\n",
    "                 {\"user\":'PhilippePoutou', \"political_party\":\"nouveau_parti_anticapitaliste\", \"political_trend\":\"extrem_left\"},\n",
    "                 {\"user\":'jfpoisson78', \"political_party\":\"la_voie_du_peuple\", \"political_trend\":\"extrem_right\"},\n",
    "                 {\"user\":'f_philippot', \"political_party\":\"les_patriotes\", \"political_trend\":\"extrem_right\"},\n",
    "                 {\"user\":'vpecresse', \"political_party\":\"soyons_libres\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'DenisPayre', \"political_party\":\"les_republicains\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'montebourg', \"political_party\":\"l_engagement\", \"political_trend\":\"left\"},\n",
    "                 {\"user\":'JLMelenchon', \"political_party\":\"la_france_insoumise\", \"political_trend\":\"extrem_left\"},\n",
    "                 {\"user\":'MLP_officiel', \"political_party\":\"front_national\", \"political_trend\":\"extrem_right\"},\n",
    "                 {\"user\":'SLeFoll', \"political_party\":\"parti_socialiste\", \"political_trend\":\"left\"},\n",
    "                 {\"user\":'jeanlassalle', \"political_party\":\"resistons\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'larrouturou', \"political_party\":\"nouvelle_donne\", \"political_trend\":\"left\"},\n",
    "                 {\"user\":'philippejuvin', \"political_party\":\"les_republicains\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'yjadot', \"political_party\":\"EELV\", \"political_trend\":\"ecology\"},\n",
    "                 {\"user\":'Anne_Hidalgo', \"political_party\":\"parti_socialiste\", \"political_trend\":\"left\"},\n",
    "                 {\"user\":'gerardfiloche', \"political_party\":\"la_gauche_democratique_et_sociale\", \"political_trend\":\"extrem_left\"},\n",
    "                 {\"user\":'dupontaignan', \"political_party\":\"debout_la_france\", \"political_trend\":\"extrem_right\"},\n",
    "                 {\"user\":'ECiotti', \"political_party\":\"les_republicains\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'xavierbertrand', \"political_party\":\"la_manufacture\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'MichelBarnier', \"political_party\":\"les_republicains\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'UPR_Asselineau', \"political_party\":\"union_populaire_republicaine\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'n_arthaud', \"political_party\":\"lutte_ouvriere\", \"political_trend\":\"extrem_left\"},\n",
    "                 {\"user\":'MartinRocca12', \"political_party\":\"constituante_2022\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'gilleslazzarini', \"political_party\":\"parti_politique_pour_la_paix_et_la_protection_de_la_planete\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'AlexLanglois_', \"political_party\":\"refondation_2022\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'luclaf', \"political_party\":\"une_perspective_la_6e_republique\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'Vukuzman', \"political_party\":\"republique_souveraine\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'FabriceGrimal', \"political_party\":\"la_concorde_citoyenne_2022\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'ClaraEgger1', \"political_party\":\"espoir_RIC_2022\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'Cau_Marie_', \"political_party\":\"sans_etiquette\", \"political_trend\":\"divers\"},\n",
    "                 {\"user\":'antoine27955080', \"political_party\":\"volontaires_pour_la_france\", \"political_trend\":\"extrem_right\"},\n",
    "                 {\"user\":'regis_ollivier', \"political_party\":\"independant\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'JaclineMouraud', \"political_party\":\"sans_etiquette\", \"political_trend\":\"right\"},\n",
    "                 {\"user\":'HeleneThouy', \"political_party\":\"parti_animaliste\", \"political_trend\":\"ecology\"},\n",
    "                 {\"user\":'MAZUEL_Pace', \"political_party\":\"pace\", \"political_trend\":\"left\"},\n",
    "                 {\"user\":'MarCharlott', \"political_party\":\"sans_etiquette\", \"political_trend\":\"left\"},\n",
    "                 {\"user\":'AguebPorterie', \"political_party\":\"aucun\", \"political_trend\":\"left\"},\n",
    "                 {\"user\":'AnasseKazib', \"political_party\":\"courant_communiste_revolutionnaire_revolution_permanente\", \"political_trend\":\"extrem_left\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f50c0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_df = pd.DataFrame(new_features)\n",
    "# new_features_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50627be5",
   "metadata": {},
   "source": [
    "### Merge it to last_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6107a148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>source_url</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>political_party</th>\n",
       "      <th>political_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1454743807824650240</td>\n",
       "      <td>1454743807824650240</td>\n",
       "      <td>À quoi sert la COP26 ? https://t.co/mcdo7zEuAG...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>constituante_2022</td>\n",
       "      <td>divers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1452597557557821440</td>\n",
       "      <td>1452597557557821440</td>\n",
       "      <td>Engagez-vous pour un réel renouvellement de no...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>constituante_2022</td>\n",
       "      <td>divers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>MartinRocca12</td>\n",
       "      <td>1452290369727647757</td>\n",
       "      <td>1452290369727647757</td>\n",
       "      <td>Ou comment l'homme le plus détesté de France p...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>constituante_2022</td>\n",
       "      <td>divers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user         author                   id               id_str  \\\n",
       "0  MartinRocca12  MartinRocca12  1454743807824650240  1454743807824650240   \n",
       "1  MartinRocca12  MartinRocca12  1452597557557821440  1452597557557821440   \n",
       "2  MartinRocca12  MartinRocca12  1452290369727647757  1452290369727647757   \n",
       "\n",
       "                                                text           source  \\\n",
       "0  À quoi sert la COP26 ? https://t.co/mcdo7zEuAG...  Twitter Web App   \n",
       "1  Engagez-vous pour un réel renouvellement de no...  Twitter Web App   \n",
       "2  Ou comment l'homme le plus détesté de France p...  Twitter Web App   \n",
       "\n",
       "                   source_url  retweet_count  favorite_count lang  \\\n",
       "0  https://mobile.twitter.com              0               1   fr   \n",
       "1  https://mobile.twitter.com              3               3   fr   \n",
       "2  https://mobile.twitter.com              0               1   fr   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_user_id_str in_reply_to_screen_name  \\\n",
       "0                  NaN                     NaN                     NaN   \n",
       "1                  NaN                     NaN                     NaN   \n",
       "2                  NaN                     NaN                     NaN   \n",
       "\n",
       "   quoted_status_id quoted_status_id_str  in_reply_to_status_id  \\\n",
       "0               NaN                  NaN                    NaN   \n",
       "1               NaN                  NaN                    NaN   \n",
       "2               NaN                  NaN                    NaN   \n",
       "\n",
       "  in_reply_to_status_id_str    political_party political_trend  \n",
       "0                       NaN  constituante_2022          divers  \n",
       "1                       NaN  constituante_2022          divers  \n",
       "2                       NaN  constituante_2022          divers  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tweets_df = pd.merge(left=last_tweets_df, right=new_features_df, on='user', how='left')\n",
    "last_tweets_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e21a21",
   "metadata": {},
   "source": [
    "## Check the number of tweets per politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb903b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_tweets_df[\"user\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084186c",
   "metadata": {},
   "source": [
    "## Add it to the main global DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e83f37",
   "metadata": {},
   "source": [
    "### Load the global_df \n",
    "- and drop the last index column automatically named \"Unamed: 0\" when saving df to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e548f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = pd.read_csv(\"global_df.csv\").drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bf739",
   "metadata": {},
   "source": [
    "### Add new content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6bc89a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just added 2894 tweets to our global_df\n"
     ]
    }
   ],
   "source": [
    "actual_number_of_tweets = global_df.shape[0]\n",
    "global_df = global_df.append(last_tweets_df, ignore_index=True)\n",
    "global_df = global_df.drop_duplicates()\n",
    "print(f\"We just added {global_df.shape[0]-actual_number_of_tweets} tweets to our global_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b34ba",
   "metadata": {},
   "source": [
    "### Save the new global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b520eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8723, 8)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67efbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.to_csv(\"global_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe632af",
   "metadata": {},
   "source": [
    "# Clean tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ec9a9",
   "metadata": {},
   "source": [
    "## Make a new df from the global one\n",
    "- This way we will be allowed to drop duplicates next time we will load the global_df from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b0fce02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10268/3143467732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_ready_for_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'global_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_ready_for_nlp = global_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeed460",
   "metadata": {},
   "source": [
    "## Retrieve recurrent regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320cc2d",
   "metadata": {},
   "source": [
    "### Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bb457d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_rt_retweets(df):\n",
    "    new_texts = []\n",
    "    \n",
    "    for text in df[\"text\"]:\n",
    "        if text[:3] == 'RT ' or text[:3] == 'rt ':\n",
    "            new_texts.append(text[3:])\n",
    "        else:\n",
    "            new_texts.append(text)\n",
    "    \n",
    "    df[\"text\"] = new_texts\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb77e4",
   "metadata": {},
   "source": [
    "- Show a text that contains this regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "218d0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_text = df_ready_for_nlp[df_ready_for_nlp[\"text\"].str.contains(\"rt \")][\"text\"].iloc[1]\n",
    "# retweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c419771",
   "metadata": {},
   "source": [
    "- Check its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2084ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_text_index = df_ready_for_nlp[df_ready_for_nlp[\"text\"]==retweet_text].index[0]\n",
    "# retweet_text_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90421c6",
   "metadata": {},
   "source": [
    "- Apply the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc232a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready_for_nlp = retrieve_rt_retweets(df_ready_for_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f133407",
   "metadata": {},
   "source": [
    "- Check if the text that contained this regex still appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72ac84d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retweet_text_cleaned = df_ready_for_nlp.iloc[retweet_text_index][\"text\"]\n",
    "# retweet_text_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090cc107",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afb64d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_links(df):\n",
    "    pattern = re.compile(\"https://*\")\n",
    "    new_text = []\n",
    "\n",
    "    for text in df[\"text\"]:\n",
    "        if re.search(pattern, text) is None:\n",
    "            new_text.append(text)\n",
    "        else:\n",
    "            match_position = re.search(pattern, text).span()[0]\n",
    "            new_text.append(text[:(match_position-1)])\n",
    "\n",
    "    df[\"text\"] = new_text\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa7b74",
   "metadata": {},
   "source": [
    "- Show a text that contains this regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b94b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_with_link = df_ready_for_nlp[df_ready_for_nlp[\"text\"].str.contains(\"https://\")][\"text\"].iloc[0]\n",
    "# text_with_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ecb8b",
   "metadata": {},
   "source": [
    "- Check its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01f86ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_with_link_index = df_ready_for_nlp[df_ready_for_nlp[\"text\"]==text_with_link].index[0]\n",
    "# text_with_link_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7502f15",
   "metadata": {},
   "source": [
    "- Apply the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c093ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready_for_nlp = retrieve_links(df_ready_for_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0b271",
   "metadata": {},
   "source": [
    "- Check if the text that contained this regex still appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c461c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_with_link_cleaned = df_ready_for_nlp.iloc[text_with_link_index][\"text\"]\n",
    "# text_with_link_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29273dd9",
   "metadata": {},
   "source": [
    "## Define a text_cleaner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55cff025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Remove Punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') \n",
    "    \n",
    "    # Lower Case\n",
    "    lowercased = text.lower() \n",
    "    \n",
    "    # Remove accents\n",
    "    unaccented_string = unidecode.unidecode(lowercased) \n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized = word_tokenize(unaccented_string) \n",
    "    \n",
    "    # Remove numbers\n",
    "    words_only = [word for word in tokenized if word.isalpha()] \n",
    "    \n",
    "    # Make stopword list\n",
    "    stop_words = set(stopwords.words('french')) \n",
    "    \n",
    "    # Remove Stop Words\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words]\n",
    "    \n",
    "    return \" \".join(without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9337316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca va etre test'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_cleaner(\"ça va être un Test!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d50d6a",
   "metadata": {},
   "source": [
    "## Apply the text_cleaner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2d4bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready_for_nlp['text'] = df_ready_for_nlp['text'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d929e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ready_for_nlp['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2077576",
   "metadata": {},
   "source": [
    "# Analyze tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680ab41",
   "metadata": {},
   "source": [
    "## Vectorize the text and estimate the associated weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "342c1544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Tuned TFidfvectorizer\n",
    "# vec = TfidfVectorizer(ngram_range = (1,1), min_df=0.01, max_df = 0.05).fit(df_ready_for_nlp[\"text\"])\n",
    "\n",
    "# # Transform text to vectors\n",
    "# vectors = vec.transform(df_ready_for_nlp[\"text\"]) \n",
    "\n",
    "# # Sum of tfidf weighting by word\n",
    "# sum_tfidf = vectors.sum(axis=0) \n",
    "\n",
    "# # Get the word and associated weight\n",
    "# tfidf_list = [(word, sum_tfidf[0, idx]) for word, idx in vec.vocabulary_.items()]  \n",
    "\n",
    "# # Sort\n",
    "# sorted_tfidf_list =sorted(tfidf_list, key = lambda x: x[1], reverse=True)  \n",
    "\n",
    "# sorted_tfidf_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876fd074",
   "metadata": {},
   "source": [
    "## Map words weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858cc0a",
   "metadata": {},
   "source": [
    "- To retrieve once again stopwords but with WordCloud, add after \"height\":\n",
    "- stopwords=STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b36d163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.subplots(figsize=(25,15))\n",
    "# wordcloud = WordCloud(background_color='white', width=1920, height=1080, stopwords=STOPWORDS).generate(\" \".join(df_ready_for_nlp[\"text\"]))\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c377183",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Count iteration per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0b44aaf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# words_iteration = {}\n",
    "\n",
    "# for text in df_ready_for_nlp[\"text\"]:\n",
    "#     tokenized_word = word_tokenize(text)\n",
    "#     for word in tokenized_word:\n",
    "#         if word in words_iteration:\n",
    "#             words_iteration[word] += 1\n",
    "#         else:\n",
    "#             words_iteration[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d83d81cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# len(words_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a9bfcce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dict(sorted(words_iteration.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f4cc9",
   "metadata": {},
   "source": [
    "## Work on lexical contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81806c1",
   "metadata": {},
   "source": [
    "### Define lexical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af5e2e",
   "metadata": {},
   "source": [
    "- Politique\n",
    "- Ecologie\n",
    "- Socialiste\n",
    "- Capitaliste\n",
    "- Communiste\n",
    "- Extreme\n",
    "- Humaniste\n",
    "- Santé\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1075831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_lexicon = \"\"\"démocratie,politicien,gouvernement,état,diplomatie,fédéralisme,constitution,socialisme,idéologie,économique,économie,libéralisme,régime,pouvoir,social,actualité,citoyen,monarchie,parti,Machiavel,pluralisme,opposition,parlement,stratégie,civique,dictature,gouvernant,machiavélisme,parti politique,réactionnaire,dépolitiser,diplomatique,fascisme,géopolitique,politiser,sionisme,homme d'État,opinion,politologue,progressiste,révolution,révolutionnaire,technocratie,apartheid,écologie,égalité,gauche,indépendance,nationalisme,oligarchie,populisme,réfugié,terrorisme,austérité,révolution,démagogie,polémique,diplomate,philosophe,politisation,grève,libéral,programme,sociologie,souveraineté,système,alliance,anarchie,autocratie,bipolarisation,congrès,opportunisme,politiquement,propagande,schisme,sénat,Union européenne,apolitique,débat,féodalité,impérialisme,leader,militant,parlementaire,politicard,scission,économiste,extrémisme,impérialiste,analyste,centriste,écologiste,immigration,machiavélique,arène,bourgeoisie,communiste,instabilité,mondialisation,pamphlet,science politique,société,culturel,dissidence,européenne,financier,journal,mission,multipartisme,panafricanisme,racisme,anarchisme,civil,crise,électeur,gaullisme,goulag,islamisme,majorité,marxiste,orientation,parti républicain,protectorat,scandale,terreur,transition,utopie,amnistie,coalition,courant,décentralisation,entente,extrémiste,gouvernementale,Mao ZeDong,municipale,philosophie,philosophique,relance,revue,statut,technocrate,bonapartiste,clientélisme,démocratique,religieuse,répression,séparatiste,souverainiste,capitalisme,conduite,conflit,idéologique,isolationnisme,juridique,morales,politologie,publiciste,autarcie,bureaucratie,cléricalisme,colonial,contexte,démocrate,dialogue,gestion,glasnost,institutionnel,politicailler,politicaillerie,stabilité,totalitaire,vie politique,agitation,anticléricalisme,appartenance,autruche,barre,bureau,centre,club,écologisme,éditorial,état-providence,gauchiste,gazette,homme,infléchir,institut,institutions,intégration,keynésianisme,modéré,monarchiste,morale,violence,orthodoxe,panslavisme,pression,prolétariat,province,sécession,tendance,totalitarisme,action,activiste,affaire,constitutionnelle,déflation,échiquier,encarté,extérieure,faction,habile,homme politique,indépendantiste,intérieure,interpellation,interventionnisme,junte,Marine Le Pen,nation,parlementarisme,public,quitter,réaction,religion,social-démocratie,souverainisme,sphère,syndicalisme,tribalisme,troïka,agrarien,ambiant,budgétaire,considérations,convictions,discrimination,droits civils,fédérale,féminisme,finance,Guépéou,intrigues,langue de bois,monétaire,nationalité,nihilisme,réforme,Tchéka,tempête,administrative,ambitions,assemblées,autonomie,classe ouvrière,commerciales,conservateur,conversion,ethnique,fédération,financement,intérêts,littérature,menées,nationale,opposant,personnalités,populiste,protectionniste,querelles,républicain,syndical,affaires publiques,artistiques,démographique,discrimination positive,gouverner,habileté,indépendantisme,négociation,plan,police,politiste,ruse,science,temporisation,Thucydide,abstentionniste,Académie des sciences,accession,activisme,agora,aliénation,ambitieuse,anarchiste,antiparlementaire,autonome,autonomiste\"\"\"\n",
    "political_lexicon = word_tokenize(text_cleaner(political_lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5ee28",
   "metadata": {},
   "source": [
    "### Define a function to count each time a twitter user user a word present in a given lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68834c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_importance_per_user_df(df, lexicon):\n",
    "    \"\"\"Return a DataFrame couting each time a twitter user use a word present in a given lexicon\"\"\"\n",
    "    # Define the users\n",
    "    list_of_users = list(df[\"user\"].unique())\n",
    "    # Define a list stocking the results per user\n",
    "    lexicon_per_user_list = []\n",
    "\n",
    "    for user in list_of_users:\n",
    "        # Define a DataFrame per user\n",
    "        users_personnal_df = df[df[\"user\"]==user]\n",
    "        # Analyze each tweet of each personnal DataFrame created\n",
    "        for text in users_personnal_df[\"text\"]:\n",
    "            # Tokenize tweets\n",
    "            tokenized_word = word_tokenize(text)\n",
    "            # Iterate over each one of them\n",
    "            for word in tokenized_word:\n",
    "                # Check if they are in a certain lexicon\n",
    "                if word in lexicon:\n",
    "                    # If it is the case, create a dictionary that stock this information\n",
    "                    new_row = {\"user\":user}\n",
    "                    # If the word is already registered in this new_row count +1\n",
    "                    if word in new_row:\n",
    "                        new_row[word] += 1\n",
    "                    # If it is the first time, only count 1\n",
    "                    else:\n",
    "                        new_row[word] = 1\n",
    "                    # Finaly, append this new_row to the lexic_per_user_list\n",
    "                    lexicon_per_user_list.append(new_row)\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    # Generate the DataFrame from the lexicon_per_user_list just created\n",
    "    lexicon_per_user_df = pd.DataFrame(lexicon_per_user_list)\n",
    "    # Fillna by 0\n",
    "    lexicon_per_user_df = lexicon_per_user_df.fillna(0)\n",
    "    # Groupby and sum the results per user\n",
    "    lexicon_per_user_df = lexicon_per_user_df.groupby(['user']).sum()\n",
    "    # Create a \"total\" column to generate a lexicon_score_per_user\n",
    "    lexicon_per_user_df[\"lexicon_score_per_user\"] = lexicon_per_user_df.sum(axis=1)\n",
    "    # Transpose the DataFrame to have the users in column and the words in row\n",
    "    lexicon_per_user_df_transposed = lexicon_per_user_df.T\n",
    "    \n",
    "    return lexicon_per_user_df_transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551170e",
   "metadata": {},
   "source": [
    "### Apply the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5d5fcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = lexicon_importance_per_user_df(df=df_ready_for_nlp, lexicon=political_lexicon)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf719d3c",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cb3a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_score = df_test[\"Anne_Hidalgo\"].sort_values(ascending=False)[0]\n",
    "user_top_words = df_test[\"Anne_Hidalgo\"].sort_values(ascending=False)[1:]\n",
    "\n",
    "for word, recurrence_results in user_top_words.items():\n",
    "    if recurrence_results == 0:\n",
    "        user_top_words = user_top_words.drop(labels=word)\n",
    "        \n",
    "top_20_user_top_words = user_top_words[:20]\n",
    "\n",
    "plot_index = list(top_20_user_top_words.index)\n",
    "plot_values = list(top_20_user_top_words.values)\n",
    "sns.barplot(x=plot_index, y=plot_values, color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "600bc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pie(plot_values, labels=plot_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868ae0b",
   "metadata": {},
   "source": [
    "### Check the words we let behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1421a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "m="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6a689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
